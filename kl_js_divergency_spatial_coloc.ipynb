{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8546933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import scipy.stats\n",
    "import random\n",
    "from itertools import *\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fclusterdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa84ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_dummy_df(data_input, col_cell_type='tangram_cell_type'):\n",
    "    \"\"\"Transform cell type long dataframe to wider table with original cell index\n",
    "    Parameters:\n",
    "    ------------\n",
    "    data_input: dataframe\n",
    "        Includes default column \"tangram_cell_type\" and index \"cell id\"\n",
    "    col_cell_type: string\n",
    "        Column name of cell type,  cell type names must be syntactically valid\n",
    "\n",
    "    Returns:\n",
    "    data_out: dataframe\n",
    "        dummy data frame with cell types on columns\n",
    "    \"\"\"\n",
    "    data_input[\"id_add\"] = data_input.index\n",
    "    data_input[\"col_add\"] = data_input[col_cell_type]\n",
    "    data_input[\"value\"] = 1\n",
    "    data_out = data_input[[\"id_add\", \"col_add\", \"value\"]].pivot_table(index=\"id_add\", columns=\"col_add\", values=\"value\",\n",
    "                                                                      fill_value=0)\n",
    "    if (data_out.index == data_input.index).all:\n",
    "        return data_out\n",
    "    else:\n",
    "        print(\"incorrect cell index \")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a83693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_grid_kern_bin(data, coord, min_num=100, h=20, n=100j, tot_num=True):\n",
    "    \"\"\" construct the map of grid from data and return Kenerl density on grid\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    data: dataframe\n",
    "        Cell type dummy table\n",
    "    coord: dataframe\n",
    "        Coordinates data with X and Y columns\n",
    "    min_num: int\n",
    "        Minimum cells count for each cell type\n",
    "    h: int\n",
    "        Bandwidths for x and y directions, more details in KernelDensity function in sklearn.neighbors package\n",
    "    n: int + j\n",
    "        Number of grid points in each direction\n",
    "    tot_num: bool to decide whether to normalize\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    data_out: dataframe with X1,X2 coords and kernel density\n",
    "        data_out with cell types columns representing kernel density in each spot.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # for cells with less than min_num, randomly add 1\n",
    "    data_ = data\n",
    "    if min_num < 0: min_num = 1\n",
    "    col_min = data.sum() < min_num\n",
    "    col_min_index = col_min[col_min].index\n",
    "    if len(col_min_index) != 0:\n",
    "        for i in range(0, len(col_min_index)):\n",
    "            random.seed(i)\n",
    "            cell_type = col_min_index[i]\n",
    "            ct_dummy_array = data_.loc[:, cell_type]\n",
    "            random_cell = random.sample(population=list(np.where(ct_dummy_array == 0)[0]),\n",
    "                                        k=min_num - ct_dummy_array.sum())\n",
    "            data_.loc[:, cell_type][random_cell] = 1\n",
    "            print(col_min_index[i] + \" cell randomly add to \" + str(data_.loc[:, col_min_index[i]].sum()) + \" cells\")\n",
    "\n",
    "    # coordinates for X1 and X2\n",
    "    coord = pd.DataFrame(coord)\n",
    "    coord.columns = ['X' + str(i) for i in range(0, len(coord.columns))]\n",
    "    coord.index = list(data_.index)\n",
    "    data_merge = pd.concat([coord, data_], axis=1)\n",
    "\n",
    "    kde2d = KernelDensity(bandwidth=h, kernel=\"gaussian\")\n",
    "    # build 2D grid as sample points\n",
    "    xx, yy = np.mgrid[data_merge['X0'].min():data_merge['X0'].max():n,\n",
    "             data_merge['X1'].min():data_merge['X1'].max():n]\n",
    "    xy_sample = pd.DataFrame(np.vstack([xx.ravel(), yy.ravel()]).T, columns=[\"X\", \"Y\"])\n",
    "    data_out = pd.DataFrame(xy_sample)\n",
    "    data_out.columns = [\"X0\", \"X1\"]\n",
    "\n",
    "    print(\"estimate gaussian kernel 2D density for each cell types...\")\n",
    "    for i in data_.columns:\n",
    "        xy_train = data_merge[[\"X0\", \"X1\"]][data_merge[i] == 1]\n",
    "        kde2d.fit(xy_train)\n",
    "        # score_samples() returns the log-likelihood of the samples\n",
    "        z = np.exp(kde2d.score_samples(xy_sample))\n",
    "\n",
    "        # plt.figure(figsize=(6,8))\n",
    "        # plt.pcolormesh(xx, yy, np.reshape(z, xx.shape), cmap=\"YlGnBu\")\n",
    "        # plt.scatter(xy_train['X0'], xy_train['X1'], s=2, facecolor=\"white\")\n",
    "        # plt.savefig(\"Cell type gaussian kernel density/\" +i+\".pdf\")\n",
    "        z = pd.DataFrame(z, columns=[i])\n",
    "        data_out = pd.concat([data_out, z], axis=1)\n",
    "\n",
    "    # data_out with cell types columns representing kernel density in each spot. (normalization)\n",
    "    if tot_num:\n",
    "        data_out = data_out.drop([\"X0\", \"X1\"], axis=1)\n",
    "        data_out = data_out / data_out.sum()\n",
    "\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad5cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_JS_Divergence(X, eps=1e-20, diver=\"KL\"):\n",
    "    \"\"\" calculate Kullback-Leibler or Jensen-Shannon diversity\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    X: dataframe\n",
    "        Density matrix\n",
    "    eps: double flout\n",
    "        small value added\n",
    "    diver: str\n",
    "        \"KL\" or \"JS\" representing Kullback-Leibler or Jensen-Shannon Divergence\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    KL_D: dataframe\n",
    "        KL-divergence matrix\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    X_ = X.fillna(eps)\n",
    "    X_[X_ < eps] = eps\n",
    "    X_ = X_ / X_.sum()\n",
    "    n_type = len(X_.columns)\n",
    "    diver_matrix = pd.DataFrame(np.zeros((n_type, n_type)))\n",
    "    diver_matrix.index = X_.columns\n",
    "    diver_matrix.columns = X_.columns\n",
    "    print(\"calculate cell types pairs \" + diver + \" divergence...\")\n",
    "    if diver == \"KL\":\n",
    "        for i in combinations(X_.columns, 2):\n",
    "            KL = scipy.stats.entropy(X_[i[0]], X_[i[1]])\n",
    "            diver_matrix.loc[i[0], i[1]] = KL\n",
    "            diver_matrix.loc[i[1], i[0]] = KL\n",
    "    else:\n",
    "        for i in combinations(X_.columns, 2):\n",
    "            M = (X_[i[0]] + X_[i[1]]) / 2\n",
    "            JS = 0.5 * scipy.stats.entropy(X_[i[0]], M, base=2) + 0.5 * scipy.stats.entropy(X_[i[1]], M, base=2)\n",
    "            diver_matrix.loc[i[0], i[1]] = JS\n",
    "            diver_matrix.loc[i[1], i[0]] = JS\n",
    "\n",
    "    return diver_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e862f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divergence_clustermap(matrix, name=\"default_divergence\", out_path='./'):\n",
    "    \"\"\" plot divergence clusterd heatmap\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    matrix: dataframe / matrix\n",
    "        divergence matrix\n",
    "    name: string\n",
    "        picture name\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    show and save picture;S\n",
    "\n",
    "    \"\"\"\n",
    "    matrix_log = -np.log(matrix)\n",
    "    # transfre -log0 (infinite) to the max value of column\n",
    "    matrix_log = matrix_log.replace(np.inf, np.nan)\n",
    "    matrix_log = matrix_log.replace(np.nan, matrix_log.max())\n",
    "    sns_plot = sns.clustermap(\n",
    "        matrix_log,\n",
    "        cmap=\"YlOrRd\",\n",
    "        linewidths=1,\n",
    "        linecolor=\"white\",\n",
    "        cbar_pos=[.8, .55, .02, .2],\n",
    "        dendrogram_ratio=0.1,\n",
    "        method=\"ward\")\n",
    "    # mask upper triangle\n",
    "    mask = np.triu(np.ones_like(matrix_log))\n",
    "    values = sns_plot.ax_heatmap.collections[0].get_array().reshape(matrix_log.shape)\n",
    "    new_values = np.ma.array(values, mask=mask)\n",
    "    sns_plot.ax_heatmap.collections[0].set_array(new_values)\n",
    "    # set left dendrogram invisible\n",
    "    sns_plot.ax_row_dendrogram.set_visible(False)\n",
    "    # set y axis ticks left\n",
    "    sns_plot.ax_heatmap.yaxis.set_ticks_position(\"left\")\n",
    "    plt.show()\n",
    "    # save figure\n",
    "    sns_plot.savefig(out_path + name + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2b3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_draw(df_adjacency, name=\"graph\", node_size=20, edge_width=1, out_path='./'):\n",
    "    \"\"\" plot network graph\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    df_adjacency: dataframe / matrix\n",
    "        adjacency matrix\n",
    "    name: string\n",
    "        picture name\n",
    "    node_size: control node size\n",
    "    edge_width: control edge width\n",
    "    out_path: output pathway\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    show and save picture;\n",
    "\n",
    "    \"\"\"\n",
    "    # create\n",
    "    G = nx.from_pandas_adjacency(df_adjacency)\n",
    "    # define position of nodes and labels\n",
    "    pos = nx.planar_layout(G)\n",
    "    labels_pos = {}\n",
    "    for key, value in pos.items():\n",
    "        random.seed(value[0])\n",
    "        labels_pos[key] = (value[0], value[1])\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.axis('off')\n",
    "    # plot nodes and edges of network graph\n",
    "    nx.draw_networkx_nodes(G, pos=pos,\n",
    "                           node_size=[1 * node_size * (item[1] + 1) for item in G.degree()],\n",
    "                           label=True, node_color=\"SteelBlue\")\n",
    "    nx.draw_networkx_edges(G, pos=pos,\n",
    "                           edge_color=[np.log(1 / d[\"weight\"]) for (u, v, d) in G.edges(data=True)],\n",
    "                           width=[np.log(1 * edge_width / d[\"weight\"]) for (u, v, d) in G.edges(data=True)],\n",
    "                           edge_cmap=plt.cm.Blues)\n",
    "    nx.draw_networkx_labels(G, pos=labels_pos, font_size=6, font_weight=\"bold\")\n",
    "    # plt.show(block=False)\n",
    "\n",
    "    # save figure\n",
    "    plt.savefig(out_path + name + '.pdf', pad_inches=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "220e7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_JS_boot_mst(dummy_df, coord_df, min_num=15, boot_n=10, prop=0.8, h=20, tot_num=True, diver=\"JS\"):\n",
    "    \"\"\"  calculate KL or JS divergence and use MST to generate a tree structure by Bootstrap\n",
    "         to obtain consensus cell types colocalization dissimilarity matrix\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    dummy_df: dataframe\n",
    "        dummy data frame with cell types on columns\n",
    "    coord_df: dataframe\n",
    "        Coordinates data with X and Y columns\n",
    "    min_num: int\n",
    "        Minimum cells count for each cell type\n",
    "    boot_n: int\n",
    "        Number of bootstraping iteration\n",
    "    prop: 0-1\n",
    "        Subsample preportion\n",
    "    diver: String\n",
    "        use KL or JS divergence\n",
    "\n",
    "    other see in sp_grid_kern_bin function\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    dis_cons: dataframe\n",
    "        Bootstrap KL/JS divergence\n",
    "    mst_cons: dataframe\n",
    "        Bootstrap MST matrix\n",
    "    dis_boot_array: array\n",
    "        Each Bootstrap result\n",
    "\n",
    "    \"\"\"\n",
    "    coord_df = pd.DataFrame(coord_df)\n",
    "    n_smp = len(dummy_df)\n",
    "    n_type = len(dummy_df.columns)\n",
    "    dis_boot_array = np.zeros((n_type, n_type, boot_n))\n",
    "    mst_cons = pd.DataFrame(np.zeros((n_type, n_type)), columns=list(dummy_df.columns), index=list(dummy_df.columns))\n",
    "    dis_cons = pd.DataFrame(np.zeros((n_type, n_type)), columns=list(dummy_df.columns), index=list(dummy_df.columns))\n",
    "    for i in range(boot_n):\n",
    "        print('---- Bootstrap ' + str(i + 1) + \" time ----\")\n",
    "        random.seed(i)\n",
    "        ## Bootstrap ##\n",
    "        idx = random.sample(range(n_smp), round(n_smp * prop))\n",
    "        data_boot = dummy_df.iloc[idx, :]\n",
    "        coord_boot = coord_df.iloc[idx, :]\n",
    "        k2d_boot = sp_grid_kern_bin(data=data_boot, coord=coord_boot, min_num=min_num, h=h, tot_num=tot_num)\n",
    "        dis_boot = KL_JS_Divergence(k2d_boot, eps=1e-20, diver=diver)\n",
    "        dis_boot_array[:, :, i] = dis_boot\n",
    "\n",
    "        # create a graph from the adjacency matrix\n",
    "        graph_boot = nx.from_pandas_adjacency(dis_boot)\n",
    "        # MST\n",
    "        graph_mst_boot = nx.minimum_spanning_tree(graph_boot)\n",
    "        mst_boot = nx.to_pandas_adjacency(graph_mst_boot)\n",
    "\n",
    "        # cumulate bootstrap\n",
    "        mst_cons = mst_cons + mst_boot / boot_n\n",
    "        dis_cons = dis_cons + dis_boot / boot_n\n",
    "\n",
    "    return dis_cons, mst_cons, dis_boot_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edeb8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_cell_types_coloc(sp_data_inp, col_cell_type=\"tangram_cell_type\", h=20, boot_n=20, out_path=\"./\"):\n",
    "    cell_type_dummy_df = as_dummy_df(sp_data_inp.obs, col_cell_type=col_cell_type)\n",
    "    dis_cons, mst_cons, dis_boot_array = KL_JS_boot_mst(dummy_df=cell_type_dummy_df,\n",
    "                                                        coord_df=sp_data_inp.obsm[\"spatial\"], h=h, boot_n=boot_n)\n",
    "    divergence_clustermap(dis_cons, name=\"cell_types_JSD\", out_path=out_path)\n",
    "    print(network_microenv(mst_cons))\n",
    "    network_draw(mst_cons, name=\"cell_types_mst_network\", out_path=out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08960355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_microenv(df_adjacency, out_path, to_cpdb=True, cutoff=0.5):\n",
    "    \"\"\" obtain cell types microenvironment\n",
    "\n",
    "        Parameters\n",
    "        ---------\n",
    "        df_adjacency: dataframe / matrix\n",
    "            divergence matrix\n",
    "        out_path: string\n",
    "            picture name\n",
    "        cutoff: number\n",
    "            filter out interaction lower than cutoff\n",
    "        to_cpdb: bool\n",
    "            whether output as CellphoneDB microenvironment file\n",
    "\n",
    "        Returns\n",
    "        ---------\n",
    "        output microenvironment file\n",
    "\n",
    "        \"\"\"\n",
    "    # init\n",
    "    microenv = pd.Series(df_adjacency.columns, index=[\"Microenv_\" + str(cell).replace(' ', '_')\n",
    "                                                      for cell in df_adjacency.columns])\n",
    "    # get top \"cutoff\" percent divergence value\n",
    "    arr_adjacency = np.array(df_adjacency).ravel()\n",
    "    arr_adjacency_nozero = []\n",
    "    for i in arr_adjacency:\n",
    "        if i != 0:\n",
    "            arr_adjacency_nozero = np.append(arr_adjacency_nozero,[i])\n",
    "    print(arr_adjacency_nozero)\n",
    "    cutoff_v = np.percentile(np.sort(arr_adjacency_nozero),cutoff*100)\n",
    "    print(cutoff_v)\n",
    "    for cell in df_adjacency.columns:\n",
    "        index = \"Microenv_\" + str(cell).replace(' ', '_')\n",
    "        # find non-zero element and correspondent cell type\n",
    "        non_zero_index = df_adjacency[cell].loc[\n",
    "            (df_adjacency[cell] != 0) & (df_adjacency[cell] < cutoff_v)\n",
    "            ].index.values\n",
    "        # add interacting cell type\n",
    "        if len(non_zero_index) != 0:\n",
    "            microenv[index] = np.append(cell, non_zero_index)\n",
    "        else:\n",
    "            microenv.drop(index, inplace=True)\n",
    "    if to_cpdb:\n",
    "        out_csv_df = pd.DataFrame(columns=['cell_type', 'microenvironment'])\n",
    "        for k, v in microenv.items():\n",
    "            v = v.reshape(len(v), 1)\n",
    "            k = np.array(str(k)).repeat(len(v)).reshape(len(v), 1)\n",
    "            out_csv_df = pd.concat(\n",
    "                [out_csv_df, pd.DataFrame(np.hstack([v, k]), columns=['cell_type', 'microenvironment'])],\n",
    "                axis=0, ignore_index=True)\n",
    "        out_csv_df.to_csv(path_or_buf=out_path + \"microenvironment.csv\", header=True, index=False, sep=',')\n",
    "        return out_csv_df\n",
    "    else:\n",
    "        return microenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba16a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Bootstrap 1 time ----\n",
      "estimate gaussian kernel 2D density for each cell types...\n",
      "calculate cell types pairs JS divergence...\n",
      "[0.0152212  0.02892154 0.06392121 0.0152212  0.00898636 0.10472587\n",
      " 0.04938011 0.04229257 0.21099645 0.05836273 0.0988005  0.05836273\n",
      " 0.05252179 0.01664076 0.12491613 0.00898636 0.01286744 0.00918682\n",
      " 0.04938011 0.21099645 0.10025646 0.04229257 0.02736805 0.10472587\n",
      " 0.02736805 0.06392121 0.05252179 0.0988005  0.01664076 0.01286744\n",
      " 0.12491613 0.00918682 0.02892154 0.10025646]\n",
      "0.049380109168399654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Microenv_Cajal-Retzius_cell              [Cajal-Retzius cell, Endothelial, VLMC]\n",
       "Microenv_Endothelial                [Endothelial, Cajal-Retzius cell, Microglia]\n",
       "Microenv_IP                                                            [IP, RG1]\n",
       "Microenv_Int2                                              [Int2, Striatal inh2]\n",
       "Microenv_Microglia             [Microglia, Endothelial, Striatal inh2, Thalamic]\n",
       "Microenv_RG1                                                      [RG1, IP, RG2]\n",
       "Microenv_RG2                                                          [RG2, RG1]\n",
       "Microenv_Striatal_inh2                          [Striatal inh2, Int2, Microglia]\n",
       "Microenv_Thalamic                                          [Thalamic, Microglia]\n",
       "Microenv_VLMC                                         [VLMC, Cajal-Retzius cell]\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_adata_annotated = sc.read('data/spatial_adata_annotated.h5ad')\n",
    "cell_type_dummy_df = as_dummy_df(spatial_adata_annotated.obs, col_cell_type=\"tangram_cell_type\")\n",
    "dis_cons, mst_cons, dis_boot_array = KL_JS_boot_mst(dummy_df=cell_type_dummy_df,\n",
    "                                                    coord_df=spatial_adata_annotated.obsm[\"spatial\"], h=20, boot_n=1)\n",
    "network_microenv(mst_cons, out_path='./', to_cpdb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1766c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
